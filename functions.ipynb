{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import numpy as np\n",
        "\n",
        "from fbprophet import Prophet\n",
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "import glob\n",
        "\n",
        "from fbprophet.diagnostics import cross_validation\n",
        "from fbprophet.diagnostics import performance_metrics\n",
        "import itertools\n",
        "\n",
        "from azureml.core import Workspace,Datastore, Dataset\n",
        "\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "\n",
        "def load_data(data_file):\n",
        "    ###\n",
        "    #### For anon data, load_data is the only function needed to change\n",
        "    #### + Update IDs in model_config\n",
        "    ###\n",
        "    \n",
        "    ### Pull from Blob\n",
        "    ws = Workspace.from_config()\n",
        "    blob_datastore_name='cesmii_datastore'\n",
        "    datastore = Datastore.get(ws, datastore_name=blob_datastore_name)\n",
        "    datastore_paths = [(datastore, data_file)]\n",
        "    ds = Dataset.Tabular.from_delimited_files(path=datastore_paths, header='ALL_FILES_HAVE_SAME_HEADERS')\n",
        "    data = ds.to_pandas_dataframe()\n",
        "    ###\n",
        "\n",
        "    data = data.loc[data[\"Transaction Type\"] == \"BK\"]\n",
        "    data['ID'] = (data[\"Plant Code\"] + '_' + data[\"Part Number\"].astype(str))\n",
        "    data.sort_values(by = 'ID',inplace = True)\n",
        "    parts = list(data[\"ID\"].unique())\n",
        "\n",
        "    data.index = pd.to_datetime(data[\"Inv Adjustment Datetime\"])\n",
        "    data_sorted = data.sort_index()\n",
        "\n",
        "    present = data_sorted.index.max().date().strftime(\"%m/%d/%Y\")\n",
        "\n",
        "    return parts, data_sorted, present\n",
        "\n",
        "def get_raw_data(data,\n",
        "                 in_ID, \n",
        "                 outlier_cutoff = ''):\n",
        "\n",
        "    data_sorted = data\n",
        "\n",
        "    print(in_ID)\n",
        "    raw_data = -1*data_sorted.loc[(data_sorted.ID == in_ID),\n",
        "                                   \"Transaction Qty\"]\n",
        "    if outlier_cutoff != '' :\n",
        "        raw_data = raw_data.loc[raw_data < outlier_cutoff]\n",
        "        \n",
        "    return raw_data\n",
        "\n",
        "\n",
        "\n",
        "def get_integrated_time( raw_data,\n",
        "                         integral_window,\n",
        "                         history_start_date,\n",
        "                         center_date,\n",
        "                         history_end_date,\n",
        "                         evaluation_frequency ):\n",
        "    \n",
        "    delta =  timedelta(days = (\n",
        "                                (pd.to_datetime(center_date) - pd.to_datetime(history_start_date)).days) %\n",
        "                                int(evaluation_frequency[0])\n",
        "                              )\n",
        "\n",
        "    start_dt = pd.to_datetime(history_start_date) + delta \n",
        "\n",
        "    date_grid = pd.date_range(\n",
        "                              start= start_dt, \n",
        "                              end= history_end_date, \n",
        "                              freq= evaluation_frequency, \n",
        "                             )\n",
        "\n",
        "    value_out = []\n",
        "\n",
        "    for date in date_grid:\n",
        "        left_window = date - timedelta(days= integral_window)\n",
        "        value_out.append(raw_data[left_window:date].sum())\n",
        "\n",
        "    integral = pd.DataFrame(value_out)\n",
        "    integral.index = date_grid\n",
        "\n",
        "    integral = integral[date_grid[0] + timedelta(days= integral_window):]\n",
        "    \n",
        "    return integral\n",
        "\n",
        "\n",
        "\n",
        "def cv_model_tune(processed_data):\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['ds'] = processed_data.index\n",
        "    df['y'] = processed_data.values\n",
        "\n",
        "    param_grid = {\n",
        "        'daily_seasonality' : [False],\n",
        "        'weekly_seasonality' : [False],\n",
        "        'yearly_seasonality' : [True],\n",
        "        'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
        "        'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
        "    }\n",
        "\n",
        "    # Generate all combinations of parameters\n",
        "    all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "    rmses = []  # Store the RMSEs for each params here\n",
        "\n",
        "    # Use cross validation to evaluate all parameters\n",
        "    for params in all_params:\n",
        "        m = Prophet(**params).fit(df)  # Fit model with given params\n",
        "        df_cv = cross_validation(m, initial='366 days',period = '15 days', horizon='365 days', parallel=\"processes\")\n",
        "        df_p = performance_metrics(df_cv, rolling_window=1)\n",
        "        rmses.append(df_p['rmse'].values[0])\n",
        "\n",
        "    # Find the best parameters\n",
        "    tuning_results = pd.DataFrame(all_params)\n",
        "    tuning_results['rmse'] = rmses\n",
        "\n",
        "    [m_daily_seasonality,\n",
        "     m_weekly_seasonality,\n",
        "     m_yearly_seasonality,\n",
        "     m_changepoint_prior_scale,\n",
        "     m_seasonality_prior_scale,\n",
        "     rmse] = tuning_results.loc[tuning_results.rmse == tuning_results.rmse.min()].values[0]\n",
        "    \n",
        "    return m_daily_seasonality, m_weekly_seasonality, m_yearly_seasonality, m_changepoint_prior_scale, m_seasonality_prior_scale, rmse\n",
        "\n",
        "\n",
        "\n",
        "def get_model_fit_line(processed_data,\n",
        "                       params):\n",
        "\n",
        "    dff = processed_data\n",
        "    data = pd.DataFrame()\n",
        "    data['ds'] = dff.index\n",
        "    data['y'] = dff.values\n",
        "\n",
        "    m = Prophet( \n",
        "                  weekly_seasonality= params['weekly_seasonality'],\n",
        "                  daily_seasonality= params['daily_seasonality'],\n",
        "                  changepoint_prior_scale =  params['changepoint_prior_scale'], \n",
        "                  changepoint_range = params['changepoint_range'], \n",
        "                  seasonality_prior_scale = params['seasonality_prior_scale'],  \n",
        "                  yearly_seasonality = params['yearly_seasonality'],\n",
        "                  interval_width=params['interval_width']\n",
        "               )\n",
        "\n",
        "    m.fit(data)\n",
        "\n",
        "    future = m.make_future_dataframe(periods=1)\n",
        "    future.tail()\n",
        "\n",
        "    forecast = m.predict(future)\n",
        "\n",
        "    fig1 = m.plot(forecast)\n",
        "\n",
        "\n",
        "\n",
        "def MAPE(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "\n",
        "    idx = (y_true!=0)\n",
        "\n",
        "    mape_score = np.mean(np.abs((y_true[idx] - y_pred[idx]) / y_true[idx]))\n",
        "\n",
        "    return mape_score\n",
        "\n",
        "\n",
        "\n",
        "def model_eval_forecast( processed_data,\n",
        "                         raw_data,\n",
        "                         center_date,\n",
        "                         forecast_horizon,\n",
        "                         params,\n",
        "                         eval_every_N_weeks = 2\n",
        "                       ):\n",
        "\n",
        "    curve_in = processed_data\n",
        "    every_N_weeks = eval_every_N_weeks\n",
        "\n",
        "    relief_forecast_results_out = []\n",
        "\n",
        "    results = pd.DataFrame(index = ['Max','Mean','Min','Std'])\n",
        "\n",
        "    mape = []\n",
        "    present = pd.to_datetime(center_date)\n",
        "    for i in range(0,52):\n",
        "        horizon = present + timedelta(days= forecast_horizon)\n",
        "\n",
        "        dff_train = curve_in[:present]    \n",
        "        dff_test = curve_in[present:horizon][1:]\n",
        "\n",
        "\n",
        "        data = pd.DataFrame()\n",
        "        data['ds'] = dff_train.index\n",
        "        data['y'] = dff_train.values\n",
        "\n",
        "        test = pd.DataFrame()\n",
        "        test['ds'] = dff_test.index\n",
        "\n",
        "        m = Prophet( \n",
        "                      yearly_seasonality=True,            \n",
        "                      weekly_seasonality= False,\n",
        "                      daily_seasonality= False,\n",
        "                      changepoint_prior_scale = params['changepoint_prior_scale'],\n",
        "                      seasonality_prior_scale = params['seasonality_prior_scale'],\n",
        "                      changepoint_range = .8,\n",
        "                   )\n",
        "\n",
        "\n",
        "\n",
        "        m.fit(data)\n",
        "\n",
        "        if dff_test.index.max() < curve_in.index.max():\n",
        "\n",
        "             forecast = m.predict(test)\n",
        "\n",
        "             mape.append(MAPE(dff_test[0],forecast.yhat))\n",
        "\n",
        "             forecast = forecast.loc[pd.to_datetime(forecast.ds) == horizon]\n",
        "\n",
        "             right_window = forecast.ds.values[0]\n",
        "             left_window = present\n",
        "\n",
        "             relief_forecast_results_out.append([\n",
        "                                                    left_window,\n",
        "                                                    right_window,\n",
        "                                                    forecast.yhat_upper.values[0],\n",
        "                                                    forecast.yhat.values[0],\n",
        "                                                    forecast.yhat_lower.values[0],\n",
        "                                                    raw_data[left_window:right_window].sum(),\n",
        "                                                ])\n",
        "\n",
        "        present = present + timedelta(weeks= every_N_weeks)\n",
        "\n",
        "    MAPE_metric = pd.DataFrame(mape)\n",
        "    Accuracy = (1 - MAPE_metric)*100\n",
        "    temp = pd.DataFrame([Accuracy.max(),Accuracy.mean(),Accuracy.min(),Accuracy.std()],index = ['Max','Mean','Min','Std'])\n",
        "    \n",
        "    results[str(forecast_horizon) + 'days'] = temp\n",
        "\n",
        "    BK_results = pd.DataFrame(relief_forecast_results_out, columns = ['now', \n",
        "                                                                      'forecast_date', \n",
        "                                                                      'High',\n",
        "                                                                      'Mean',\n",
        "                                                                      'Low',\n",
        "                                                                      'Actual']\n",
        "                              )\n",
        "\n",
        "    BK_results['error'] = ((BK_results.Mean - BK_results.Actual)/BK_results.Actual)\n",
        "    \n",
        "    return [results, BK_results]\n",
        "\n",
        "\n",
        "\n",
        "def model_forecast(processed_data,\n",
        "                   forecast_horizon,\n",
        "                   params,\n",
        "                   evaluation_frequency):\n",
        "\n",
        "    dff_train = processed_data\n",
        "\n",
        "    data = pd.DataFrame()\n",
        "    data['ds'] = dff_train.index\n",
        "    data['y'] = dff_train.values\n",
        "\n",
        "    future_index = pd.date_range(\n",
        "                                  start= processed_data.index[-1], \n",
        "                                  end= processed_data.index[-1] + timedelta(days= forecast_horizon), \n",
        "                                  freq= evaluation_frequency \n",
        "                                 )\n",
        "\n",
        "    forecast_index = processed_data.index\n",
        "\n",
        "    eval_index = pd.DataFrame()\n",
        "    eval_index['ds'] = forecast_index.append(future_index[1:])\n",
        "\n",
        "    m = Prophet(yearly_seasonality=True,            \n",
        "                weekly_seasonality= False,\n",
        "                daily_seasonality= False,\n",
        "                changepoint_prior_scale = params['changepoint_prior_scale'],\n",
        "                seasonality_prior_scale = params['seasonality_prior_scale'],\n",
        "                changepoint_range = .8,\n",
        "               )\n",
        "\n",
        "    m.fit(data)\n",
        "\n",
        "    forecast = m.predict(eval_index)\n",
        "\n",
        "    right_window = [forecast.iloc[-1].ds][0]\n",
        "    left_window = [forecast.iloc[-1].ds][0] - timedelta(days= forecast_horizon)\n",
        "\n",
        "\n",
        "    left_window,\n",
        "    right_window,\n",
        "    forecast_value = forecast.iloc[-1].yhat\n",
        "    \n",
        "    return left_window, right_window, forecast_value\n",
        "    \n",
        "    \n",
        "\n",
        "def get_forecast_metrics(forecast_actuals):\n",
        "    coverage = (sum((forecast_actuals.Actual < forecast_actuals.High) & (forecast_actuals.Actual > forecast_actuals.Low))/len(forecast_actuals))*100\n",
        "    forecast_MAPE = forecast_actuals.error.abs().mean()*100\n",
        "    forecast_MAPE_std = forecast_actuals.error.abs().std()*100\n",
        "    forecast_mean_error = forecast_actuals.error.mean()*100\n",
        "    forecast_std_error = forecast_actuals.error.std()*100\n",
        "    \n",
        "    return coverage, forecast_mean_error, forecast_std_error, forecast_MAPE, forecast_MAPE_std\n",
        "\n",
        "def get_part_descriptors(in_ID, data):\n",
        "\n",
        "    data['ID'] = (data[\"Plant Code\"] + '_' + data[\"Part Number\"].astype(str))\n",
        "    \n",
        "    data_sorted = data\n",
        "    \n",
        "    descriptor = data_sorted.loc[(data_sorted.ID == in_ID) &\n",
        "                                 (data_sorted[\"Transaction Type\"] == \"BK\"),\n",
        "                                             [\"Commodity Description\",\n",
        "                                              \"Sub Commodity Description\", \n",
        "                                              \"Primary Supplier Name\", \n",
        "                                              \"Part Description\"]].iloc[0]\n",
        "        \n",
        "    return list(descriptor.values)\n",
        "\n",
        "##PART OF MAIN CALL##\n",
        "\n",
        "def instance_eval(data, PRESENT, MODEL_CONFIG_FILE):\n",
        "\n",
        "    model_config = pd.read_csv('./files/model_cvs/' + MODEL_CONFIG_FILE, low_memory=False, index_col=False).fillna('')\n",
        "\n",
        "    center_date = (data.index.max() - timedelta(days= 364)).date().strftime(\"%m/%d/%Y\")\n",
        "\n",
        "    model_eval = pd.DataFrame([], columns = [   'part_ID', \n",
        "                                                'outlier_cutoff', \n",
        "                                                'start_date', \n",
        "                                                'center_date',\n",
        "                                                'present', \n",
        "                                                'evaluation_frequency', \n",
        "                                                'forecast_window', \n",
        "                                                'model_eval_every_N_weeks',\n",
        "                                                'm_changepoint_prior_scale',\n",
        "                                                'm_seasonality_prior_scale',\n",
        "                                                'goodness_fit_Max',\n",
        "                                                'goodness_fit_Mean',\n",
        "                                                'goodness_fit_Min',\n",
        "                                                'goodness_fit_Std',\n",
        "                                                'forecast_mean_error',\n",
        "                                                'forecast_std_error',\n",
        "                                                'forecast_MAPE',\n",
        "                                                'forecast_MAPE_std',\n",
        "                                                'N_test_points'\n",
        "                                            ])\n",
        "\n",
        "    for curve in model_config.iterrows():\n",
        "        \n",
        "        part_ID = curve[1].part_ID\n",
        "        forecast_horizon = curve[1].forecast_window\n",
        "        outlier_cutoff = curve[1].outlier_cutoff\n",
        "        start_date = curve[1].start_date\n",
        "        evaluation_frequency = curve[1].evaluation_frequency\n",
        "        end_date = PRESENT\n",
        "        model_eval_every_N_weeks = 1\n",
        "        \n",
        "        \n",
        "        raw_data = get_raw_data(\n",
        "                                data,\n",
        "                                part_ID, \n",
        "                                outlier_cutoff\n",
        "                            )\n",
        "\n",
        "        processed_data = get_integrated_time( raw_data,\n",
        "                                            forecast_horizon,\n",
        "                                            start_date,\n",
        "                                            center_date,\n",
        "                                            end_date,\n",
        "                                            evaluation_frequency )\n",
        "\n",
        "        parameters = { \n",
        "                    'changepoint_prior_scale' : curve[1].m_changepoint_prior_scale,  \n",
        "                    'seasonality_prior_scale': curve[1].m_seasonality_prior_scale,\n",
        "                    }\n",
        "\n",
        "        [goodness_fit, forecast_actuals] = model_eval_forecast(  \n",
        "                                                                processed_data,\n",
        "                                                                raw_data,\n",
        "                                                                center_date,\n",
        "                                                                forecast_horizon ,\n",
        "                                                                params = parameters,\n",
        "                                                                eval_every_N_weeks = model_eval_every_N_weeks\n",
        "                                                            )\n",
        "\n",
        "        _, mean_error, std_error, MAPE_score, MAPE_std = get_forecast_metrics(forecast_actuals)\n",
        "\n",
        "        temp = pd.DataFrame(   [part_ID, \n",
        "                                outlier_cutoff, \n",
        "                                start_date, \n",
        "                                center_date, \n",
        "                                end_date, \n",
        "                                evaluation_frequency, \n",
        "                                forecast_horizon, \n",
        "                                model_eval_every_N_weeks,\n",
        "                                parameters['changepoint_prior_scale'],\n",
        "                                parameters['seasonality_prior_scale'],\n",
        "                                goodness_fit.loc['Max'].values[0],\n",
        "                                goodness_fit.loc['Mean'].values[0],\n",
        "                                goodness_fit.loc['Min'].values[0],\n",
        "                                goodness_fit.loc['Std'].values[0],\n",
        "                                mean_error, \n",
        "                                std_error,\n",
        "                                MAPE_score,\n",
        "                                MAPE_std,\n",
        "                                len(forecast_actuals)]\n",
        "\n",
        "                            ).transpose()\n",
        "\n",
        "        temp.columns = [    'part_ID', \n",
        "                            'outlier_cutoff', \n",
        "                            'start_date', \n",
        "                            'center_date',\n",
        "                            'present', \n",
        "                            'evaluation_frequency', \n",
        "                            'forecast_window', \n",
        "                            'model_eval_every_N_weeks',\n",
        "                            'm_changepoint_prior_scale',\n",
        "                            'm_seasonality_prior_scale',\n",
        "                            'goodness_fit_Max',\n",
        "                            'goodness_fit_Mean',\n",
        "                            'goodness_fit_Min',\n",
        "                            'goodness_fit_Std',\n",
        "                            'forecast_mean_error',\n",
        "                            'forecast_std_error',\n",
        "                            'forecast_MAPE',\n",
        "                            'forecast_MAPE_std',\n",
        "                            'N_test_points'\n",
        "                        ]\n",
        "\n",
        "        model_eval = model_eval.append(temp)\n",
        "\n",
        "    return model_eval\n",
        "\n",
        "def forecast_instance(data, model_eval):\n",
        "\n",
        "    forecasts = pd.DataFrame([], columns = [ 'part_ID', \n",
        "                                            'present', \n",
        "                                            'forecast_window',\n",
        "                                            'forecast_date',\n",
        "                                            'forecast_value',\n",
        "                                            'historical_mean_error',\n",
        "                                            'historical_error_std',\n",
        "                                            'forecast_MAPE',\n",
        "                                            'accuracy',\n",
        "                                            'forecast_low',\n",
        "                                            'forecast_high',\n",
        "                                            'Commodity Description',\n",
        "                                            'Sub Commodity Description', \n",
        "                                            'Primary Supplier Name', \n",
        "                                            'Part Description']\n",
        "                            )\n",
        "\n",
        "    z = 1.44 #85% percentile\n",
        "    forecast_present = model_eval.present.iloc[0]\n",
        "\n",
        "    for instance in model_eval.iterrows():     \n",
        "\n",
        "        in_ID = instance[1].part_ID\n",
        "        outlier_cutoff = instance[1].outlier_cutoff\n",
        "        forecast_window = int(instance[1].forecast_window)\n",
        "        start_date = instance[1].start_date\n",
        "        evaluation_frequency = instance[1].evaluation_frequency\n",
        "\n",
        "        center_date = forecast_present\n",
        "        end_date = forecast_present\n",
        "\n",
        "        parameters = { \n",
        "                    'changepoint_prior_scale' : instance[1].m_changepoint_prior_scale, \n",
        "                    'seasonality_prior_scale': instance[1].m_seasonality_prior_scale,  \n",
        "                    }\n",
        "\n",
        "        raw_data = get_raw_data(\n",
        "                                data,\n",
        "                                in_ID, \n",
        "                                outlier_cutoff\n",
        "                            )\n",
        "\n",
        "        processed_data = get_integrated_time( raw_data,                                     \n",
        "                                            forecast_window,\n",
        "                                            start_date,\n",
        "                                            center_date,\n",
        "                                            end_date,\n",
        "                                            evaluation_frequency\n",
        "                                            )\n",
        "\n",
        "        present, forecast_date, forecast_value = model_forecast(\n",
        "                                                                processed_data,\n",
        "                                                                forecast_window,\n",
        "                                                                parameters,\n",
        "                                                                evaluation_frequency\n",
        "                                                            )\n",
        "\n",
        "        output = [[\n",
        "                    in_ID, \n",
        "                    present, \n",
        "                    forecast_window, \n",
        "                    forecast_date, \n",
        "                    int(forecast_value), \n",
        "                    round(instance[1].forecast_mean_error,2),\n",
        "                    round(instance[1].forecast_std_error,2),\n",
        "                    round(instance[1].forecast_MAPE,2),\n",
        "                    round(100 - instance[1].forecast_MAPE,2),\n",
        "                    max(int(forecast_value*(1 - (z*instance[1].forecast_std_error/100))),0),\n",
        "                    int(forecast_value*(1 + (z*instance[1].forecast_std_error/100)))]\n",
        "                    + get_part_descriptors(in_ID, data)\n",
        "                ]\n",
        "\n",
        "        temp = pd.DataFrame(output, columns = ['part_ID', \n",
        "                                            'present', \n",
        "                                            'forecast_window',\n",
        "                                            'forecast_date',\n",
        "                                            'forecast_value',\n",
        "                                            'historical_mean_error',\n",
        "                                            'historical_error_std',\n",
        "                                            'forecast_MAPE',\n",
        "                                            'accuracy',\n",
        "                                            'forecast_low',\n",
        "                                            'forecast_high',\n",
        "                                            'Commodity Description',\n",
        "                                            'Sub Commodity Description', \n",
        "                                            'Primary Supplier Name', \n",
        "                                            'Part Description']\n",
        "                            )\n",
        "        \n",
        "\n",
        "        forecasts = forecasts.append(temp)\n",
        "\n",
        "    return forecasts[['part_ID',\n",
        "                      'present',\n",
        "                      'forecast_window',\n",
        "                      'forecast_date',\n",
        "                      'forecast_low',\n",
        "                      'forecast_value',\n",
        "                      'forecast_high',\n",
        "                      'accuracy',\n",
        "                      'Commodity Description',\n",
        "                      'Sub Commodity Description', \n",
        "                      'Primary Supplier Name', \n",
        "                      'Part Description']]\n",
        "\n",
        "def check_for_update(PRESENT):\n",
        "    files = glob.glob('./files/model_evals/model_eval_*')\n",
        "\n",
        "    if len(files) > 0:\n",
        "        chk = 1\n",
        "        for csv in files:\n",
        "            date = re.sub(r'_', r'/',csv.split('eval_')[-1][0:-4])\n",
        "            chk = chk*(pd.to_datetime(PRESENT) >= pd.to_datetime(date))\n",
        "    else:\n",
        "        chk = 0\n",
        "        \n",
        "    return chk == 0\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1643730527104
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}